{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/Users/marinelegall/code/lewagon/data/07-ML-Ops/02-Cloud-training/train-in-the-cloud/\"\n",
    "sys.path.append(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/marinelegall/code/lewagon/data/07-ML-Ops/02-Cloud-training/train-in-the-cloud/taxifare/interface',\n",
       " '/Users/marinelegall/code/lewagon/data/04-Decision-Science/01-Project-Setup/context-and-setup',\n",
       " '/Users/marinelegall/code/lewagon/data/07-ML-Ops/02-Cloud-training/train-in-the-cloud/taxifare/interface',\n",
       " '/Users/marinelegall/code/lewagon/data/05-ML/10-Natural-Language-Processing/ham_or_spam',\n",
       " '/Users/marinelegall/.pyenv/versions/3.10.6/lib/python310.zip',\n",
       " '/Users/marinelegall/.pyenv/versions/3.10.6/lib/python3.10',\n",
       " '/Users/marinelegall/.pyenv/versions/3.10.6/lib/python3.10/lib-dynload',\n",
       " '',\n",
       " '/Users/marinelegall/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages',\n",
       " '/Users/marinelegall/code/lewagon/data/07-ML-Ops/02-Cloud-training/train-in-the-cloud/']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the environment here first\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path='/Users/marinelegall/code/lewagon/data/07-ML-Ops/02-Cloud-training/train-in-the-cloud/.env')\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Loading TensorFlow...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 13:08:05.226875: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ TensorFlow loaded (13.77s)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from colorama import Fore, Style\n",
    "from dateutil.parser import parse\n",
    "\n",
    "from taxifare.params import *\n",
    "from taxifare.ml_logic.data import get_data_with_cache, clean_data, load_data_to_bq\n",
    "from taxifare.ml_logic.model import initialize_model, compile_model, train_model, evaluate_model\n",
    "from taxifare.ml_logic.preprocessor import preprocess_features\n",
    "from taxifare.ml_logic.registry import load_model, save_model, save_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(min_date:str = '2009-01-01', max_date:str = '2015-01-01') -> None:\n",
    "    \"\"\"\n",
    "    - Query the raw dataset from Le Wagon's BigQuery dataset\n",
    "    - Cache query result as a local CSV if it doesn't exist locally\n",
    "    - Process query data\n",
    "    - Store processed data on your personal BQ (truncate existing table if it exists)\n",
    "    - No need to cache processed data as CSV (it will be cached when queried back from BQ during training)\n",
    "    \"\"\"\n",
    "\n",
    "    print(Fore.MAGENTA + \"\\n ‚≠êÔ∏è Use case: preprocess\" + Style.RESET_ALL)\n",
    "\n",
    "    # Query raw data from BigQuery using `get_data_with_cache`\n",
    "    min_date = parse(min_date).strftime('%Y-%m-%d') # e.g '2009-01-01'\n",
    "    max_date = parse(max_date).strftime('%Y-%m-%d') # e.g '2009-01-01'\n",
    "\n",
    "    query = f\"\"\"\n",
    "        SELECT {\",\".join(COLUMN_NAMES_RAW)}\n",
    "        FROM `{GCP_PROJECT_WAGON}`.{BQ_DATASET}.raw_{DATA_SIZE}\n",
    "        WHERE pickup_datetime BETWEEN '{min_date}' AND '{max_date}'\n",
    "        ORDER BY pickup_datetime\n",
    "    \"\"\"\n",
    "\n",
    "    # Where nothing else\n",
    "\n",
    "    # Retrieve `query` data from BigQuery or from `data_query_cache_path` if the file already exists!\n",
    "    data_query_cache_path = Path(LOCAL_DATA_PATH).joinpath(\"raw\", f\"query_{min_date}_{max_date}_{DATA_SIZE}.csv\")\n",
    "    data_query_cached_exists = data_query_cache_path.is_file()\n",
    "\n",
    "    if data_query_cached_exists:\n",
    "        print(\"Loading data from local CSV...\")\n",
    "\n",
    "        data = pd.read_csv(data_query_cache_path)\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(\"Loading data from Querying Big Query server...\")\n",
    "        from google.cloud import bigquery\n",
    "\n",
    "        client = bigquery.Client(project=GCP_PROJECT)\n",
    "        query_job = client.query(query)\n",
    "        result = query_job.result()\n",
    "        data = result.to_dataframe()\n",
    "\n",
    "        # Save it locally to accelerate the next queries!\n",
    "        data.to_csv(data_query_cache_path, header=True, index=False)\n",
    "\n",
    "    # Process data\n",
    "    # Clean data using data.py\n",
    "    data_clean = clean_data(data)\n",
    "    X = data_clean.drop(\"fare_amount\", axis=1)\n",
    "    X_processed = preprocess_features(X)\n",
    "\n",
    "    # Load a DataFrame onto BigQuery containing [pickup_datetime, X_processed, y]\n",
    "    # using data.load_data_to_bq()\n",
    "\n",
    "    return data, X_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\n",
      " ‚≠êÔ∏è Use case: preprocess\u001b[0m\n",
      "Loading data from local CSV...\n",
      "‚úÖ data cleaned\n",
      "\u001b[34m\n",
      "Preprocessing features...\u001b[0m\n",
      "‚úÖ X_processed, with shape (447, 65)\n"
     ]
    }
   ],
   "source": [
    "data, X_processed = preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(447, 65)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_processed)\n",
    "X_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[[\"pickup_datetime\"]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['fare_amount']\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 455 and the array at index 1 has size 447",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfare_amount\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m data_processed_with_timestamp \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpickup_datetime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_processed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      9\u001b[0m data_processed_with_timestamp\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 455 and the array at index 1 has size 447"
     ]
    }
   ],
   "source": [
    "y = data['fare_amount']\n",
    "\n",
    "data_processed_with_timestamp = pd.DataFrame(np.concatenate((\n",
    "        data[[\"pickup_datetime\"]],\n",
    "        X_processed,\n",
    "        y,\n",
    "    ), axis=1))\n",
    "\n",
    "data_processed_with_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_chunks_from_monday(min_date:str = '2009-01-01', max_date:str = '2015-01-01') -> None:\n",
    "    \"\"\"\n",
    "    - Query the raw dataset from Le Wagon's BigQuery dataset\n",
    "    - Cache query result as a local CSV if it doesn't exist locally\n",
    "    - Process query data\n",
    "    - Store processed data on your personal BQ (truncate existing table if it exists)\n",
    "    - No need to cache processed data as CSV (it will be cached when queried back from BQ during training)\n",
    "    \"\"\"\n",
    "\n",
    "    print(Fore.MAGENTA + \"\\n ‚≠êÔ∏è Use case: preprocess\" + Style.RESET_ALL)\n",
    "\n",
    "    # Query raw data from BigQuery using `get_data_with_cache`\n",
    "    min_date = parse(min_date).strftime('%Y-%m-%d') # e.g '2009-01-01'\n",
    "    max_date = parse(max_date).strftime('%Y-%m-%d') # e.g '2009-01-01'\n",
    "\n",
    "    query = f\"\"\"\n",
    "        SELECT {\",\".join(COLUMN_NAMES_RAW)}\n",
    "        FROM `{GCP_PROJECT_WAGON}`.{BQ_DATASET}.raw_{DATA_SIZE}\n",
    "        WHERE pickup_datetime BETWEEN '{min_date}' AND '{max_date}'\n",
    "        ORDER BY pickup_datetime\n",
    "    \"\"\"\n",
    "\n",
    "    # Where nothing else\n",
    "\n",
    "    # Retrieve `query` data from BigQuery or from `data_query_cache_path` if the file already exists!\n",
    "    data_query_cache_path = Path(LOCAL_DATA_PATH).joinpath(\"raw\", f\"query_{min_date}_{max_date}_{DATA_SIZE}.csv\")\n",
    "    data_query_cached_exists = data_query_cache_path.is_file()\n",
    "    data_processed_path = Path(LOCAL_DATA_PATH).joinpath(\"processed\", f\"processed_{min_date}_{max_date}_{DATA_SIZE}.csv\")\n",
    "    data_query_cache_exists = data_query_cache_path.is_file()\n",
    "\n",
    "    if data_query_cached_exists:\n",
    "        print(\"Loading data from local CSV...\")\n",
    "        data = pd.read_csv(data_query_cache_path)\n",
    "        chunks = None\n",
    "\n",
    "        # $CODE_BEGIN\n",
    "        chunks = pd.read_csv(\n",
    "            data_query_cache_path,\n",
    "            chunksize=200, #CHUNK_SIZE\n",
    "            parse_dates=[\"pickup_datetime\"])\n",
    "\n",
    "    # if:\n",
    "        # else:\n",
    "        #     print(\"Loading data from Querying Big Query server...\")\n",
    "            # from google.cloud import bigquery\n",
    "\n",
    "        #     client = bigquery.Client(project=GCP_PROJECT)\n",
    "        #     query_job = client.query(query)\n",
    "        #     result = query_job.result()\n",
    "        #     data = result.to_dataframe()\n",
    "\n",
    "        #     # Save it locally to accelerate the next queries!\n",
    "        #     data.to_csv(data_query_cache_path, header=True, index=False)\n",
    "\n",
    "        # # Process data\n",
    "        # # Clean data using data.py\n",
    "        # data_clean = clean_data(data)\n",
    "        # X = data.drop(\"fare_amount\", axis=1)\n",
    "        # X_preprocessed = preprocess_features(X)\n",
    "\n",
    "        # y = data['fare_amount']\n",
    "\n",
    "        # # Load a DataFrame onto BigQuery containing [pickup_datetime, X_processed, y]\n",
    "        # # using data.load_data_to_bq()\n",
    "\n",
    "        # data_processed_with_timestamp = pd.DataFrame(np.concatenate((\n",
    "        #     data_clean[[\"pickup_datetime\"]],\n",
    "        #     X_preprocessed,\n",
    "        #     y,\n",
    "        # ), axis=1))\n",
    "        # # Shape error\n",
    "    else:\n",
    "        from google.cloud import bigquery\n",
    "        print(\"Get a DataFrame iterable from querying the BigQuery server...\")\n",
    "        chunks = None\n",
    "\n",
    "        # üéØ HINT: `bigquery.Client(...).query(...).result(page_size=...).to_dataframe_iterable()`\n",
    "        # $CODE_BEGIN\n",
    "        client = bigquery.Client(project=GCP_PROJECT)\n",
    "\n",
    "        query_job = client.query(query)\n",
    "        result = query_job.result(page_size=CHUNK_SIZE)\n",
    "\n",
    "        chunks = result.to_dataframe_iterable()\n",
    "\n",
    "    for chunk_id, chunk in enumerate(chunks):\n",
    "        print(f\"Processing chunk {chunk_id}...\")\n",
    "\n",
    "        # Clean chunk\n",
    "        # $CODE_BEGIN\n",
    "        chunk_clean = clean_data(chunk)\n",
    "        # $CODE_END\n",
    "\n",
    "        # Create chunk_processed\n",
    "        # üéØ HINT: create (`X_chunk`, `y_chunk`), process only `X_processed_chunk`, then concatenate (X_processed_chunk, y_chunk)\n",
    "        # $CODE_BEGIN\n",
    "        X_chunk = chunk_clean.drop(\"fare_amount\", axis=1)\n",
    "        y_chunk = chunk_clean[[\"fare_amount\"]]\n",
    "        X_processed_chunk = preprocess_features(X_chunk)\n",
    "\n",
    "        chunk_processed = pd.DataFrame(np.concatenate((X_processed_chunk, y_chunk), axis=1))\n",
    "        # $CODE_END\n",
    "\n",
    "        # Save and append the processed chunk to a local CSV at \"data_processed_path\"\n",
    "        # üéØ HINT: df.to_csv(mode=...)\n",
    "        # üéØ HINT: we want a CSV with neither index nor headers (they'd be meaningless)\n",
    "        # $CODE_BEGIN\n",
    "        chunk_processed.to_csv(\n",
    "            data_processed_path,\n",
    "            mode=\"w\" if chunk_id==0 else \"a\",\n",
    "            header=False,\n",
    "            index=False,\n",
    "        )\n",
    "        # $CODE_END\n",
    "\n",
    "        # Save and append the raw chunk `if not data_query_cache_exists`\n",
    "        # $CODE_BEGIN\n",
    "        # üéØ HINT: we want a CSV with headers this time\n",
    "        # üéØ HINT: only the first chunk should store headers\n",
    "        if not data_query_cache_exists:\n",
    "            chunk.to_csv(\n",
    "                data_query_cache_path,\n",
    "                mode=\"w\" if chunk_id==0 else \"a\",\n",
    "                header=True if chunk_id==0 else False,\n",
    "                index=False\n",
    "            )\n",
    "        # $CODE_END\n",
    "\n",
    "    print(f\"‚úÖ data query saved as {data_query_cache_path}\")\n",
    "    print(\"‚úÖ preprocess() done\")\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\n",
      " ‚≠êÔ∏è Use case: preprocess\u001b[0m\n",
      "Loading data from local CSV...\n",
      "Processing chunk 0...\n",
      "‚úÖ data cleaned\n",
      "\u001b[34m\n",
      "Preprocessing features...\u001b[0m\n",
      "‚úÖ X_processed, with shape (196, 65)\n",
      "Processing chunk 1...\n",
      "‚úÖ data cleaned\n",
      "\u001b[34m\n",
      "Preprocessing features...\u001b[0m\n",
      "‚úÖ X_processed, with shape (197, 65)\n",
      "Processing chunk 2...\n",
      "‚úÖ data cleaned\n",
      "\u001b[34m\n",
      "Preprocessing features...\u001b[0m\n",
      "‚úÖ X_processed, with shape (54, 65)\n",
      "‚úÖ data query saved as /Users/marinelegall/.lewagon/mlops/data/raw/query_2009-01-01_2015-01-01_1k.csv\n",
      "‚úÖ preprocess() done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.9</td>\n",
       "      <td>2009-01-15 09:22:39+00:00</td>\n",
       "      <td>-73.955013</td>\n",
       "      <td>40.780784</td>\n",
       "      <td>-73.964862</td>\n",
       "      <td>40.768096</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.1</td>\n",
       "      <td>2009-01-20 10:05:35+00:00</td>\n",
       "      <td>-73.983992</td>\n",
       "      <td>40.740018</td>\n",
       "      <td>-73.975250</td>\n",
       "      <td>40.749208</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.6</td>\n",
       "      <td>2009-01-25 03:17:05+00:00</td>\n",
       "      <td>-73.987612</td>\n",
       "      <td>40.749694</td>\n",
       "      <td>-73.950233</td>\n",
       "      <td>40.780101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.3</td>\n",
       "      <td>2009-01-26 18:18:38+00:00</td>\n",
       "      <td>-74.011112</td>\n",
       "      <td>40.713399</td>\n",
       "      <td>-74.001300</td>\n",
       "      <td>40.721281</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.2</td>\n",
       "      <td>2009-01-31 03:59:43+00:00</td>\n",
       "      <td>-73.999552</td>\n",
       "      <td>40.728320</td>\n",
       "      <td>-73.926824</td>\n",
       "      <td>40.864947</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>12.5</td>\n",
       "      <td>2014-11-24 19:37:20+00:00</td>\n",
       "      <td>-73.995305</td>\n",
       "      <td>40.725196</td>\n",
       "      <td>-74.016585</td>\n",
       "      <td>40.708135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>52.5</td>\n",
       "      <td>2014-11-24 22:40:00+00:00</td>\n",
       "      <td>-74.005060</td>\n",
       "      <td>40.720610</td>\n",
       "      <td>-73.838890</td>\n",
       "      <td>40.663380</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>7.5</td>\n",
       "      <td>2014-12-09 07:19:44+00:00</td>\n",
       "      <td>-73.985858</td>\n",
       "      <td>40.761979</td>\n",
       "      <td>-73.973105</td>\n",
       "      <td>40.764185</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2014-12-27 15:34:00+00:00</td>\n",
       "      <td>-74.006780</td>\n",
       "      <td>40.735680</td>\n",
       "      <td>-74.003780</td>\n",
       "      <td>40.726100</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>8.5</td>\n",
       "      <td>2014-12-27 16:47:42+00:00</td>\n",
       "      <td>-73.978609</td>\n",
       "      <td>40.764980</td>\n",
       "      <td>-73.964241</td>\n",
       "      <td>40.771264</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     fare_amount            pickup_datetime  pickup_longitude  \\\n",
       "0            8.9  2009-01-15 09:22:39+00:00        -73.955013   \n",
       "1            4.1  2009-01-20 10:05:35+00:00        -73.983992   \n",
       "2           10.6  2009-01-25 03:17:05+00:00        -73.987612   \n",
       "3            8.3  2009-01-26 18:18:38+00:00        -74.011112   \n",
       "4           38.2  2009-01-31 03:59:43+00:00        -73.999552   \n",
       "..           ...                        ...               ...   \n",
       "450         12.5  2014-11-24 19:37:20+00:00        -73.995305   \n",
       "451         52.5  2014-11-24 22:40:00+00:00        -74.005060   \n",
       "452          7.5  2014-12-09 07:19:44+00:00        -73.985858   \n",
       "453          6.5  2014-12-27 15:34:00+00:00        -74.006780   \n",
       "454          8.5  2014-12-27 16:47:42+00:00        -73.978609   \n",
       "\n",
       "     pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0          40.780784         -73.964862         40.768096                1  \n",
       "1          40.740018         -73.975250         40.749208                1  \n",
       "2          40.749694         -73.950233         40.780101                1  \n",
       "3          40.713399         -74.001300         40.721281                1  \n",
       "4          40.728320         -73.926824         40.864947                1  \n",
       "..               ...                ...               ...              ...  \n",
       "450        40.725196         -74.016585         40.708135                1  \n",
       "451        40.720610         -73.838890         40.663380                2  \n",
       "452        40.761979         -73.973105         40.764185                2  \n",
       "453        40.735680         -74.003780         40.726100                4  \n",
       "454        40.764980         -73.964241         40.771264                4  \n",
       "\n",
       "[455 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = preprocess_chunks_from_monday()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_solution(min_date:str = '2009-01-01', max_date:str = '2015-01-01') -> None:\n",
    "    \"\"\"\n",
    "    - Query the raw dataset from Le Wagon's BigQuery dataset\n",
    "    - Cache query result as a local CSV if it doesn't exist locally\n",
    "    - Process query data\n",
    "    - Store processed data on your personal BQ (truncate existing table if it exists)\n",
    "    - No need to cache processed data as CSV (it will be cached when queried back from BQ during training)\n",
    "    \"\"\"\n",
    "\n",
    "    print(Fore.MAGENTA + \"\\n ‚≠êÔ∏è Use case: preprocess\" + Style.RESET_ALL)\n",
    "\n",
    "    # Query raw data from BigQuery using `get_data_with_cache`\n",
    "    min_date = parse(min_date).strftime('%Y-%m-%d') # e.g '2009-01-01'\n",
    "    max_date = parse(max_date).strftime('%Y-%m-%d') # e.g '2009-01-01'\n",
    "\n",
    "    query = f\"\"\"\n",
    "        SELECT {\",\".join(COLUMN_NAMES_RAW)}\n",
    "        FROM `{GCP_PROJECT_WAGON}`.{BQ_DATASET}.raw_{DATA_SIZE}\n",
    "        WHERE pickup_datetime BETWEEN '{min_date}' AND '{max_date}'\n",
    "        ORDER BY pickup_datetime\n",
    "    \"\"\"\n",
    "\n",
    "    # $CHA_BEGIN\n",
    "    # Retrieve data using `get_data_with_cache`\n",
    "    data_query_cache_path = Path(LOCAL_DATA_PATH).joinpath(\"raw\", f\"query_{min_date}_{max_date}_{DATA_SIZE}.csv\")\n",
    "    data_query = get_data_with_cache(\n",
    "        query=query,\n",
    "        gcp_project=GCP_PROJECT,\n",
    "        cache_path=data_query_cache_path,\n",
    "        data_has_header=True\n",
    "    )\n",
    "    # $CHA_END\n",
    "\n",
    "    # Process data\n",
    "    # $CHA_BEGIN\n",
    "    data_clean = clean_data(data_query)\n",
    "\n",
    "    X = data_clean.drop(\"fare_amount\", axis=1)\n",
    "    y = data_clean[[\"fare_amount\"]]\n",
    "\n",
    "    X_processed = preprocess_features(X)\n",
    "\n",
    "    # $CHA_END\n",
    "    # Load a DataFrame onto BigQuery containing [pickup_datetime, X_processed, y]\n",
    "    # using data.load_data_to_bq()\n",
    "    # $CHA_BEGIN\n",
    "    data_processed_with_timestamp = pd.DataFrame(np.concatenate((\n",
    "        data_clean[[\"pickup_datetime\"]],\n",
    "        X_processed,\n",
    "        y,\n",
    "    ), axis=1))\n",
    "\n",
    "    load_data_to_bq(\n",
    "        data_processed_with_timestamp,\n",
    "        gcp_project=GCP_PROJECT,\n",
    "        bq_dataset=BQ_DATASET,\n",
    "        table=f'processed_{DATA_SIZE}',\n",
    "        truncate=True\n",
    "    )\n",
    "    return data_processed_with_timestamp\n",
    "    # $CHA_END\n",
    "\n",
    "    print(\"‚úÖ preprocess() done \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\n",
      " ‚≠êÔ∏è Use case: preprocess\u001b[0m\n",
      "\u001b[34m\n",
      "Load data from local CSV...\u001b[0m\n",
      "‚úÖ Data loaded, with shape (455, 7)\n",
      "‚úÖ data cleaned\n",
      "\u001b[34m\n",
      "Preprocessing features...\u001b[0m\n",
      "‚úÖ X_processed, with shape (447, 65)\n",
      "\u001b[34m\n",
      "Save data to BigQuery @ wagon-paris-1812.taxifare.processed_1k...:\u001b[0m\n",
      "‚úÖ Data saved to bigquery, with shape (447, 67)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-15 09:22:39+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-20 10:05:35+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-25 03:17:05+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-26 18:18:38+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-31 03:59:43+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>2014-11-24 19:37:20+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>2014-11-24 22:40:00+00:00</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>2014-12-09 07:19:44+00:00</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>2014-12-27 15:34:00+00:00</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>2014-12-27 16:47:42+00:00</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>447 rows √ó 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0         1    2    3    4    5    6    7    8   \\\n",
       "0   2009-01-15 09:22:39+00:00       0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "1   2009-01-20 10:05:35+00:00       0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2   2009-01-25 03:17:05+00:00       0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "3   2009-01-26 18:18:38+00:00       0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4   2009-01-31 03:59:43+00:00       0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "..                        ...       ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "442 2014-11-24 19:37:20+00:00       0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "443 2014-11-24 22:40:00+00:00  0.142857  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "444 2014-12-09 07:19:44+00:00  0.142857  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "445 2014-12-27 15:34:00+00:00  0.428571  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "446 2014-12-27 16:47:42+00:00  0.428571  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "\n",
       "      9   ...   57   58   59   60   61   62   63   64   65         66  \n",
       "0    1.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0        8.9  \n",
       "1    1.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0        4.1  \n",
       "2    1.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       10.6  \n",
       "3    1.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0        8.3  \n",
       "4    1.0  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  38.200001  \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...        ...  \n",
       "442  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       12.5  \n",
       "443  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       52.5  \n",
       "444  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0        7.5  \n",
       "445  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0        6.5  \n",
       "446  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0        8.5  \n",
       "\n",
       "[447 rows x 67 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_solution = preprocess_solution()\n",
    "data_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-15 09:22:39+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-20 10:05:35+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-25 03:17:05+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-26 18:18:38+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-31 03:59:43+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>2014-11-24 19:37:20+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>2014-11-24 22:40:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>2014-12-09 07:19:44+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>2014-12-27 15:34:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>2014-12-27 16:47:42+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>447 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0\n",
       "0   2009-01-15 09:22:39+00:00\n",
       "1   2009-01-20 10:05:35+00:00\n",
       "2   2009-01-25 03:17:05+00:00\n",
       "3   2009-01-26 18:18:38+00:00\n",
       "4   2009-01-31 03:59:43+00:00\n",
       "..                        ...\n",
       "442 2014-11-24 19:37:20+00:00\n",
       "443 2014-11-24 22:40:00+00:00\n",
       "444 2014-12-09 07:19:44+00:00\n",
       "445 2014-12-27 15:34:00+00:00\n",
       "446 2014-12-27 16:47:42+00:00\n",
       "\n",
       "[447 rows x 1 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_solution[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.9</td>\n",
       "      <td>2009-01-15 09:22:39+00:00</td>\n",
       "      <td>-73.955013</td>\n",
       "      <td>40.780784</td>\n",
       "      <td>-73.964862</td>\n",
       "      <td>40.768096</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.1</td>\n",
       "      <td>2009-01-20 10:05:35+00:00</td>\n",
       "      <td>-73.983992</td>\n",
       "      <td>40.740018</td>\n",
       "      <td>-73.975250</td>\n",
       "      <td>40.749208</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.6</td>\n",
       "      <td>2009-01-25 03:17:05+00:00</td>\n",
       "      <td>-73.987612</td>\n",
       "      <td>40.749694</td>\n",
       "      <td>-73.950233</td>\n",
       "      <td>40.780101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.3</td>\n",
       "      <td>2009-01-26 18:18:38+00:00</td>\n",
       "      <td>-74.011112</td>\n",
       "      <td>40.713399</td>\n",
       "      <td>-74.001300</td>\n",
       "      <td>40.721281</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.2</td>\n",
       "      <td>2009-01-31 03:59:43+00:00</td>\n",
       "      <td>-73.999552</td>\n",
       "      <td>40.728320</td>\n",
       "      <td>-73.926824</td>\n",
       "      <td>40.864947</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>12.5</td>\n",
       "      <td>2014-11-24 19:37:20+00:00</td>\n",
       "      <td>-73.995305</td>\n",
       "      <td>40.725196</td>\n",
       "      <td>-74.016585</td>\n",
       "      <td>40.708135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>52.5</td>\n",
       "      <td>2014-11-24 22:40:00+00:00</td>\n",
       "      <td>-74.005060</td>\n",
       "      <td>40.720610</td>\n",
       "      <td>-73.838890</td>\n",
       "      <td>40.663380</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>7.5</td>\n",
       "      <td>2014-12-09 07:19:44+00:00</td>\n",
       "      <td>-73.985858</td>\n",
       "      <td>40.761979</td>\n",
       "      <td>-73.973105</td>\n",
       "      <td>40.764185</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2014-12-27 15:34:00+00:00</td>\n",
       "      <td>-74.006780</td>\n",
       "      <td>40.735680</td>\n",
       "      <td>-74.003780</td>\n",
       "      <td>40.726100</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>8.5</td>\n",
       "      <td>2014-12-27 16:47:42+00:00</td>\n",
       "      <td>-73.978609</td>\n",
       "      <td>40.764980</td>\n",
       "      <td>-73.964241</td>\n",
       "      <td>40.771264</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     fare_amount            pickup_datetime  pickup_longitude  \\\n",
       "0            8.9  2009-01-15 09:22:39+00:00        -73.955013   \n",
       "1            4.1  2009-01-20 10:05:35+00:00        -73.983992   \n",
       "2           10.6  2009-01-25 03:17:05+00:00        -73.987612   \n",
       "3            8.3  2009-01-26 18:18:38+00:00        -74.011112   \n",
       "4           38.2  2009-01-31 03:59:43+00:00        -73.999552   \n",
       "..           ...                        ...               ...   \n",
       "450         12.5  2014-11-24 19:37:20+00:00        -73.995305   \n",
       "451         52.5  2014-11-24 22:40:00+00:00        -74.005060   \n",
       "452          7.5  2014-12-09 07:19:44+00:00        -73.985858   \n",
       "453          6.5  2014-12-27 15:34:00+00:00        -74.006780   \n",
       "454          8.5  2014-12-27 16:47:42+00:00        -73.978609   \n",
       "\n",
       "     pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0          40.780784         -73.964862         40.768096                1  \n",
       "1          40.740018         -73.975250         40.749208                1  \n",
       "2          40.749694         -73.950233         40.780101                1  \n",
       "3          40.713399         -74.001300         40.721281                1  \n",
       "4          40.728320         -73.926824         40.864947                1  \n",
       "..               ...                ...               ...              ...  \n",
       "450        40.725196         -74.016585         40.708135                1  \n",
       "451        40.720610         -73.838890         40.663380                2  \n",
       "452        40.761979         -73.973105         40.764185                2  \n",
       "453        40.735680         -74.003780         40.726100                4  \n",
       "454        40.764980         -73.964241         40.771264                4  \n",
       "\n",
       "[455 rows x 7 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(min_date:str = '2009-01-01', max_date:str = '2015-01-01') -> None:\n",
    "    \"\"\"\n",
    "    - Query the raw dataset from Le Wagon's BigQuery dataset\n",
    "    - Cache query result as a local CSV if it doesn't exist locally\n",
    "    - Process query data\n",
    "    - Store processed data on your personal BQ (truncate existing table if it exists)\n",
    "    - No need to cache processed data as CSV (it will be cached when queried back from BQ during training)\n",
    "    \"\"\"\n",
    "\n",
    "    print(Fore.MAGENTA + \"\\n ‚≠êÔ∏è Use case: preprocess\" + Style.RESET_ALL)\n",
    "\n",
    "    # Query raw data from BigQuery using `get_data_with_cache`\n",
    "    min_date = parse(min_date).strftime('%Y-%m-%d') # e.g '2009-01-01'\n",
    "    max_date = parse(max_date).strftime('%Y-%m-%d') # e.g '2009-01-01'\n",
    "\n",
    "    query = f\"\"\"\n",
    "        SELECT {\",\".join(COLUMN_NAMES_RAW)}\n",
    "        FROM `{GCP_PROJECT_WAGON}`.{BQ_DATASET}.raw_{DATA_SIZE}\n",
    "        WHERE pickup_datetime BETWEEN '{min_date}' AND '{max_date}'\n",
    "        ORDER BY pickup_datetime\n",
    "    \"\"\"\n",
    "\n",
    "    # $CHA_BEGIN\n",
    "    # Retrieve data using `get_data_with_cache`\n",
    "    data_query_cache_path = Path(LOCAL_DATA_PATH).joinpath(\"raw\", f\"query_{min_date}_{max_date}_{DATA_SIZE}.csv\")\n",
    "    data_query = get_data_with_cache(\n",
    "        query=query,\n",
    "        gcp_project=GCP_PROJECT,\n",
    "        cache_path=data_query_cache_path,\n",
    "        data_has_header=True\n",
    "    )\n",
    "    # $CHA_END\n",
    "\n",
    "    # Process data\n",
    "    # $CHA_BEGIN\n",
    "    data_clean = clean_data(data_query)\n",
    "\n",
    "    X = data_clean.drop(\"fare_amount\", axis=1)\n",
    "    y = data_clean[[\"fare_amount\"]]\n",
    "\n",
    "    X_processed = preprocess_features(X)\n",
    "\n",
    "    # $CHA_END\n",
    "    # Load a DataFrame onto BigQuery containing [pickup_datetime, X_processed, y]\n",
    "    # using data.load_data_to_bq()\n",
    "    # $CHA_BEGIN\n",
    "    data_processed_with_timestamp = pd.DataFrame(np.concatenate((\n",
    "        data_clean[[\"pickup_datetime\"]],\n",
    "        X_processed,\n",
    "        y,\n",
    "    ), axis=1))\n",
    "\n",
    "    load_data_to_bq(\n",
    "        data_processed_with_timestamp,\n",
    "        gcp_project=GCP_PROJECT,\n",
    "        bq_dataset=BQ_DATASET,\n",
    "        table=f'processed_{DATA_SIZE}',\n",
    "        truncate=True\n",
    "    )\n",
    "    # $CHA_END\n",
    "\n",
    "    print(\"‚úÖ preprocess() done \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\n",
      " ‚≠êÔ∏è Use case: preprocess\u001b[0m\n",
      "\u001b[34m\n",
      "Load data from local CSV...\u001b[0m\n",
      "‚úÖ Data loaded, with shape (455, 7)\n",
      "‚úÖ data cleaned\n",
      "\u001b[34m\n",
      "Preprocessing features...\u001b[0m\n",
      "‚úÖ X_processed, with shape (447, 65)\n",
      "\u001b[34m\n",
      "Save data to BigQuery @ wagon-paris-1812.taxifare.processed_1k...:\u001b[0m\n",
      "‚úÖ Data saved to bigquery, with shape (447, 67)\n",
      "‚úÖ preprocess() done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR TRAIN\n",
    "def preprocess(min_date:str = '2009-01-01', max_date:str = '2015-01-01') -> None:\n",
    "    \"\"\"\n",
    "    - Query the raw dataset from Le Wagon's BigQuery dataset\n",
    "    - Cache query result as a local CSV if it doesn't exist locally\n",
    "    - Process query data\n",
    "    - Store processed data on your personal BQ (truncate existing table if it exists)\n",
    "    - No need to cache processed data as CSV (it will be cached when queried back from BQ during training)\n",
    "    \"\"\"\n",
    "    print(Fore.MAGENTA + \"\\n ‚≠êÔ∏è Use case: preprocess\" + Style.RESET_ALL)\n",
    "\n",
    "    # Query raw data from BigQuery using `get_data_with_cache`\n",
    "    min_date = parse(min_date).strftime('%Y-%m-%d') # e.g '2009-01-01'\n",
    "    max_date = parse(max_date).strftime('%Y-%m-%d') # e.g '2009-01-01'\n",
    "\n",
    "    query = f\"\"\"\n",
    "        SELECT {\",\".join(COLUMN_NAMES_RAW)}\n",
    "        FROM `{GCP_PROJECT_WAGON}`.{BQ_DATASET}.raw_{DATA_SIZE}\n",
    "        WHERE pickup_datetime BETWEEN '{min_date}' AND '{max_date}'\n",
    "        ORDER BY pickup_datetime\n",
    "    \"\"\"\n",
    "\n",
    "    # $CHA_BEGIN\n",
    "    # Retrieve data using `get_data_with_cache`\n",
    "    data_query_cache_path = Path(LOCAL_DATA_PATH).joinpath(\"raw\", f\"query_{min_date}_{max_date}_{DATA_SIZE}.csv\")\n",
    "    data_query = get_data_with_cache(\n",
    "        query=query,\n",
    "        gcp_project=GCP_PROJECT,\n",
    "        cache_path=data_query_cache_path,\n",
    "        data_has_header=True\n",
    "    )\n",
    "    # $CHA_END\n",
    "\n",
    "    # Process data\n",
    "    # $CHA_BEGIN\n",
    "    data_clean = clean_data(data_query)\n",
    "\n",
    "    X = data_clean.drop(\"fare_amount\", axis=1)\n",
    "    y = data_clean[[\"fare_amount\"]]\n",
    "\n",
    "    X_processed = preprocess_features(X)\n",
    "\n",
    "    # $CHA_END\n",
    "    # Load a DataFrame onto BigQuery containing [pickup_datetime, X_processed, y]\n",
    "    # using data.load_data_to_bq()\n",
    "    # $CHA_BEGIN\n",
    "    data_processed_with_timestamp = pd.DataFrame(np.concatenate((\n",
    "        data_clean[[\"pickup_datetime\"]],\n",
    "        X_processed,\n",
    "        y,\n",
    "    ), axis=1))\n",
    "\n",
    "    load_data_to_bq(\n",
    "        data_processed_with_timestamp,\n",
    "        gcp_project=GCP_PROJECT,\n",
    "        bq_dataset=BQ_DATASET,\n",
    "        table=f'processed_{DATA_SIZE}',\n",
    "        truncate=True\n",
    "    )\n",
    "    # $CHA_END\n",
    "\n",
    "    print(\"‚úÖ preprocess() done \\n\")\n",
    "    return X_processed,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\n",
      " ‚≠êÔ∏è Use case: preprocess\u001b[0m\n",
      "\u001b[34m\n",
      "Load data from local CSV...\u001b[0m\n",
      "‚úÖ Data loaded, with shape (455, 7)\n",
      "‚úÖ data cleaned\n",
      "\u001b[34m\n",
      "Preprocessing features...\u001b[0m\n",
      "‚úÖ X_processed, with shape (447, 65)\n",
      "\u001b[34m\n",
      "Save data to BigQuery @ wagon-paris-1812.taxifare.processed_1k...:\u001b[0m\n",
      "‚úÖ Data saved to bigquery, with shape (447, 67)\n",
      "‚úÖ preprocess() done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_processed, y = preprocess()\n",
    "data_cleaned = pd.DataFrame(X_processed).merge(y, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>fare_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>439 rows √ó 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0    1    2    3    4    5    6    7    8    9  ...   56   57  \\\n",
       "0    0.000000  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  ...  0.0  0.0   \n",
       "1    0.000000  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...  0.0  0.0   \n",
       "2    0.000000  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  ...  0.0  0.0   \n",
       "3    0.000000  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...  0.0  0.0   \n",
       "4    0.000000  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...  0.0  0.0   \n",
       "..        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "442  0.000000  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "443  0.142857  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "444  0.142857  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "445  0.428571  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "446  0.428571  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "\n",
       "      58   59   60   61   62   63   64  fare_amount  \n",
       "0    0.0  0.0  0.0  0.0  0.0  0.0  0.0     8.900000  \n",
       "1    0.0  0.0  0.0  0.0  0.0  0.0  0.0     4.100000  \n",
       "2    0.0  0.0  0.0  0.0  0.0  0.0  0.0    10.600000  \n",
       "3    0.0  0.0  0.0  0.0  0.0  0.0  0.0     8.300000  \n",
       "4    1.0  0.0  0.0  0.0  0.0  0.0  0.0    38.200001  \n",
       "..   ...  ...  ...  ...  ...  ...  ...          ...  \n",
       "442  0.0  0.0  0.0  0.0  0.0  0.0  0.0    11.000000  \n",
       "443  0.0  0.0  0.0  0.0  0.0  0.0  0.0     6.500000  \n",
       "444  0.0  0.0  0.0  0.0  0.0  0.0  0.0    13.500000  \n",
       "445  0.0  0.0  0.0  0.0  0.0  0.0  0.0    10.500000  \n",
       "446  0.0  0.0  0.0  0.0  0.0  0.0  0.0     7.500000  \n",
       "\n",
       "[439 rows x 66 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
